"""Team Leader graph nodes."""

import logging
import re
from pathlib import Path
from uuid import UUID

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from app.agents.team_leader.src.state import TeamLeaderState
from app.agents.team_leader.src.schemas import ExtractedPreferences, RoutingDecision
from app.agents.core.prompt_utils import (
    load_prompts_yaml, get_task_prompts as _get_task_prompts,
    build_system_prompt as _build_system_prompt, build_user_prompt as _build_user_prompt,
)

logger = logging.getLogger(__name__)

_PROMPTS = load_prompts_yaml(Path(__file__).parent / "prompts.yaml")
_DEFAULTS = {"name": "Team Leader", "role": "Team Leader & Project Coordinator", "personality": "Professional and helpful"}
_fast_llm = ChatOpenAI(model="claude-haiku-4-5-20251001", temperature=0.1, timeout=15)
_chat_llm = ChatOpenAI(model="claude-haiku-4-5-20251001", temperature=0.7, timeout=30)
    
ROLE_WIP_MAP = {"developer": "InProgress", "tester": "Review", "business_analyst": None}

# Patterns to detect specialist task completion - must be specific completion messages
# Format: (role, [(pattern, is_completion_message)])
SPECIALIST_COMPLETION_PATTERNS = {
    "business_analyst": [
        "ƒë√£ th√™m",  # "ƒê√£ th√™m X User Stories v√†o backlog"
        "stories v√†o backlog",
        "ƒë√£ ph√™ duy·ªát",
    ],
    "developer": [
        "implement xong",
        "code xong", 
        "ƒë√£ merge",
        "pull request ƒë√£ ƒë∆∞·ª£c merge",
    ],
    "tester": [
        "test xong",
        "qa xong",
        "all tests passed",
        "ƒë√£ test xong",
    ],
}


def _detect_specialist_completion(conversation_history: str) -> str | None:
    """Detect if a specialist JUST completed a task (check LAST assistant message only).
    
    Conversation history format from ProjectContext.format_memory():
    ```
    ## G·∫ßn ƒë√¢y:
    User: message
    Assistant: message
    ```
    
    Returns:
        specialist_role if detected, None otherwise
    """
    if not conversation_history:
        return None
    
    # Parse conversation to get LAST Assistant message only
    lines = conversation_history.strip().split('\n')
    
    # Find last Assistant message (format: "Assistant: message")
    last_assistant_msg = None
    for line in reversed(lines):
        line_stripped = line.strip()
        # Match "Assistant: ..." format from format_memory()
        if line_stripped.startswith('Assistant:'):
            last_assistant_msg = line_stripped[len('Assistant:'):].strip()
            break
    
    if not last_assistant_msg:
        return None
    
    last_msg_lower = last_assistant_msg.lower()
    
    # Check each role's completion patterns
    for role, patterns in SPECIALIST_COMPLETION_PATTERNS.items():
        for pattern in patterns:
            if pattern.lower() in last_msg_lower:
                return role
    
    return None


def _clean_json(text: str) -> str:
    """Strip markdown code blocks from LLM response."""
    match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    return match.group(1).strip() if match else text.strip()


def _cfg(state: dict, name: str) -> dict | None:
    h = state.get("langfuse_handler")
    return {"callbacks": [h], "run_name": name} if h else None


def _prompts(task: str = "routing_decision") -> dict:
    return _get_task_prompts(_PROMPTS, task)


def _sys_prompt(agent, task: str = "routing_decision") -> str:
    return _build_system_prompt(_PROMPTS, task, agent, _DEFAULTS)


def _user_prompt(msg: str, task: str = "routing_decision", **kw) -> str:
    return _build_user_prompt(_PROMPTS, task, msg, **kw)


async def extract_preferences(state: TeamLeaderState, agent=None) -> dict:
    """Extract and save user preferences. Returns empty dict (no state update)."""
    msg = state.get("user_message", "")
    if len(msg.strip()) < 10:
        return {}
    try:
        prompts = _prompts("preference_extraction")
        response = await _fast_llm.ainvoke(
            [SystemMessage(content=prompts["system_prompt"]), HumanMessage(content=f'Analyze: "{msg}"')],
            config=_cfg(state, "extract_preferences")
        )
        clean_json = _clean_json(response.content)
        result = ExtractedPreferences.model_validate_json(clean_json)
        detected = {k: v for k, v in result.model_dump().items() if v and k != "additional"}
        if result.additional:
            detected.update(result.additional)
        if detected and agent:
            for k, v in detected.items():
                await agent.update_preference(k, v)
    except Exception as e:
        logger.debug(f"[extract_preferences] {e}")
    return {}


async def _check_domain_change(user_message: str, existing_prd_title: str, state: dict) -> bool:
    """Use LLM to check if user request is for a different domain than existing PRD."""
    try:
        prompt = f"""So s√°nh 2 project sau v√† x√°c ƒë·ªãnh xem ch√∫ng c√≥ C√ôNG DOMAIN hay KH√ÅC DOMAIN.

Project hi·ªán t·∫°i: "{existing_prd_title}"
Y√™u c·∫ßu m·ªõi c·ªßa user: "{user_message}"

C√ôNG DOMAIN: N·∫øu user mu·ªën update, s·ª≠a ƒë·ªïi, th√™m feature cho project hi·ªán t·∫°i.
V√ç D·ª§: "Website b√°n s√°ch" + "th√™m feature gi·ªè h√†ng" = C√ôNG DOMAIN

KH√ÅC DOMAIN: N·∫øu user mu·ªën t·∫°o m·ªôt project ho√†n to√†n m·ªõi, kh√°c lƒ©nh v·ª±c.
V√ç D·ª§: "Website b√°n s√°ch" + "t·∫°o website qu·∫£n l√Ω c√¥ng vi·ªác" = KH√ÅC DOMAIN

Tr·∫£ l·ªùi CH·ªà m·ªôt t·ª´: SAME ho·∫∑c DIFFERENT"""

        response = await _fast_llm.ainvoke(
            [HumanMessage(content=prompt)],
            config=_cfg(state, "check_domain_change")
        )
        answer = response.content.strip().upper()
        return "DIFFERENT" in answer
    except Exception as e:
        logger.error(f"[_check_domain_change] Error: {e}")
        return False


async def router(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Route request using structured LLM output."""
    try:
        # Get actual board state
        board_state = ""
        if agent and hasattr(agent, 'context'):
            try:
                _, _, wip = agent.context.get_kanban_context()
                board_state = f"WIP: InProgress={wip.get('InProgress', '?')}, Review={wip.get('Review', '?')}"
            except Exception:
                pass
        
        messages = [
            SystemMessage(content=_sys_prompt(agent)),
            HumanMessage(content=_user_prompt(
                state["user_message"],
                name=agent.name if agent else "Team Leader",
                conversation_history=state.get("conversation_history", ""),
                user_preferences=state.get("user_preferences", ""),
                board_state=board_state,
            ))
        ]
        
        response = await _fast_llm.ainvoke(messages, config=_cfg(state, "router"))
        clean_json = _clean_json(response.content)
        decision = RoutingDecision.model_validate_json(clean_json)
        logger.info(f"[router] Decision: action={decision.action}, target={decision.target_role}")
        result = decision.model_dump()
        
        if result["action"] == "DELEGATE":
            wip_col = ROLE_WIP_MAP.get(result.get("target_role"))
            if wip_col and agent and hasattr(agent, 'context'):
                _, _, wip_available = agent.context.get_kanban_context()
                if wip_available.get(wip_col, 1) <= 0:
                    return {**state, "action": "RESPOND", "wip_blocked": True,
                            "message": f"Hi·ªán t·∫°i {wip_col} ƒëang full. C·∫ßn ƒë·ª£i stories ho√†n th√†nh.", "confidence": 0.95}
            
            # Check for domain change when delegating to BA
            if result.get("target_role") == "business_analyst" and agent:
                try:
                    from sqlmodel import Session
                    from app.core.db import engine
                    from app.services.artifact_service import ArtifactService
                    from app.models import ArtifactType, Epic, Story
                    
                    project_id = UUID(state["project_id"])
                    
                    with Session(engine) as session:
                        artifact_service = ArtifactService(session)
                        existing_prd = artifact_service.get_latest_version(
                            project_id=project_id,
                            artifact_type=ArtifactType.PRD
                        )
                        
                        if existing_prd:
                            # Check if domains are different
                            is_different = await _check_domain_change(
                                state["user_message"],
                                existing_prd.title,
                                state
                            )
                            
                            if is_different:
                                # Count existing stories
                                from sqlmodel import select
                                stories_count = session.exec(
                                    select(Story).where(Story.project_id == project_id)
                                ).all()
                                
                                logger.info(
                                    f"[router] Domain change detected: '{existing_prd.title}' ‚Üí new request. "
                                    f"Asking for confirmation."
                                )
                                
                                return {
                                    **state,
                                    "action": "CONFIRM_REPLACE",
                                    "existing_prd_title": existing_prd.title,
                                    "existing_stories_count": len(stories_count),
                                    "needs_replace_confirm": True,
                                    "wip_blocked": False
                                }
                except Exception as e:
                    logger.error(f"[router] Error checking domain change: {e}", exc_info=True)
        
        return {**state, **result, "wip_blocked": False}
    except Exception as e:
        logger.error(f"[router] {e}", exc_info=True)
        return {**state, "action": "RESPOND", "message": "Xin l·ªói, c√≥ l·ªói x·∫£y ra.", "confidence": 0.0, "wip_blocked": False}


async def delegate(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Delegate task to specialist agent."""
    if agent:
        from app.agents.core.base_agent import TaskContext
        from app.kafka.event_schemas import AgentTaskType
        
        msg = state.get("message") or f"Chuy·ªÉn cho @{state['target_role']} nh√©!"
        await agent.message_user("response", msg)
        
        task = TaskContext(
            task_id=UUID(state["task_id"]), task_type=AgentTaskType.MESSAGE, priority="high",
            routing_reason=state.get("reason", "team_leader_routing"),
            user_id=UUID(state["user_id"]) if state.get("user_id") else None,
            project_id=UUID(state["project_id"]), content=state["user_message"],
        )
        await agent.delegate_to_role(task=task, target_role=state["target_role"], delegation_message=msg)
    return {**state, "action": "DELEGATE"}


async def respond(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Send direct response to user."""
    msg = state.get("message", "M√¨nh c√≥ th·ªÉ gi√∫p g√¨?")
    if agent:
        await agent.message_user("response", msg)
    return {**state, "action": "RESPOND"}


async def clarify(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Ask clarification question using LLM with persona."""
    try:
        reason = state.get("reason", "need more details")
        hint = state.get("clarification_question", "")
        
        sys_prompt = _sys_prompt(agent, "conversational")
        user_prompt = f"""User v·ª´a n√≥i: "{state['user_message']}"

M√¨nh c·∫ßn h·ªèi clarification v√¨: {reason}
{f'G·ª£i √Ω c√¢u h·ªèi: {hint}' if hint else ''}

H√£y vi·∫øt M·ªòT c√¢u h·ªèi clarification th√¢n thi·ªán, t·ª± nhi√™n ƒë·ªÉ hi·ªÉu r√µ h∆°n user mu·ªën g√¨.
- Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao c·∫ßn th√™m info
- G·ª£i √Ω c·ª• th·ªÉ user c·∫ßn cung c·∫•p g√¨ (feature name, error message, steps...)
- D√πng emoji ph√π h·ª£p"""

        response = await _chat_llm.ainvoke(
            [SystemMessage(content=sys_prompt), HumanMessage(content=user_prompt)],
            config=_cfg(state, "clarify")
        )
        question = response.content
    except Exception as e:
        logger.error(f"[clarify] LLM error: {e}")
        question = state.get("message") or "Hmm, m√¨nh c·∫ßn bi·∫øt r√µ h∆°n ch√∫t! ü§î B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n kh√¥ng?"
    
    if agent:
        await agent.message_user("response", question)
    return {**state, "message": question, "action": "CLARIFY"}


async def conversational(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Generate conversational response."""
    try:
        conversation_history = state.get("conversation_history", "")
        
        # Detect if specialist just completed a task
        specialist_role = _detect_specialist_completion(conversation_history)
        
        # Build context for LLM
        sys_prompt = _sys_prompt(agent, "conversational")
        
        # Add specialist completion context if detected
        specialist_context = ""
        if specialist_role:
            role_names = {
                "business_analyst": "Business Analyst",
                "developer": "Developer", 
                "tester": "Tester"
            }
            role_display = role_names.get(specialist_role, specialist_role)
            specialist_context = f"""
**L∆ØU √ù QUAN TR·ªåNG:** {role_display} v·ª´a ho√†n th√†nh task. B·∫°n ƒëang ti·∫øp qu·∫£n cu·ªôc h·ªôi tho·∫°i.
- H√£y ch√†o ƒë√≥n user tr·ªü l·∫°i m·ªôt c√°ch t·ª± nhi√™n
- C√≥ th·ªÉ h·ªèi user c·∫ßn g√¨ ti·∫øp theo
- ƒê·ª´ng l·∫∑p l·∫°i nh·ªØng g√¨ {role_display} ƒë√£ n√≥i"""
        
        if conversation_history:
            sys_prompt += f"""

---

**Cu·ªôc tr√≤ chuy·ªán g·∫ßn ƒë√¢y:**
{conversation_history}
{specialist_context}

**L∆∞u √Ω:** D·ª±a v√†o context tr√™n ƒë·ªÉ tr·∫£ l·ªùi t·ª± nhi√™n v√† li√™n quan. ƒê·ª´ng l·∫∑p l·∫°i nh·ªØng g√¨ ƒë√£ n√≥i."""
        
        response = await _chat_llm.ainvoke(
            [SystemMessage(content=sys_prompt), HumanMessage(content=state["user_message"])],
            config=_cfg(state, "conversational")
        )
        if agent:
            await agent.message_user("response", response.content)
        return {**state, "message": response.content, "action": "CONVERSATION"}
    except Exception as e:
        logger.error(f"[conversational] {e}")
        msg = "Hmm, c√≥ g√¨ ƒë√≥ kh√¥ng ·ªïn. B·∫°n th·ª≠ l·∫°i ƒë∆∞·ª£c kh√¥ng? üòÖ"
        if agent:
            await agent.message_user("response", msg)
        return {**state, "message": msg, "action": "CONVERSATION"}


async def status_check(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Check board status using tool-calling agent."""
    try:
        from langchain.agents import create_agent
        from app.agents.team_leader.tools import get_team_leader_tools
        
        status_agent = create_agent(model=_chat_llm, tools=get_team_leader_tools(), system_prompt=_sys_prompt(agent, "status_check"))
        result = await status_agent.ainvoke(
            {"messages": [{"role": "user", "content": f"{state.get('user_message', '')}\n\nproject_id: {state.get('project_id', '')}"}]},
            config=_cfg(state, "status_check")
        )
        msg = result["messages"][-1].content
        if agent:
            await agent.message_user("response", msg)
        return {**state, "message": msg, "action": "STATUS_CHECK"}
    except Exception as e:
        logger.error(f"[status_check] {e}")
        return {**state, "message": "", "action": "STATUS_CHECK"}


async def confirm_replace(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Ask user to confirm replacing existing project with new one."""
    try:
        existing_title = state.get("existing_prd_title", "project hi·ªán t·∫°i")
        stories_count = state.get("existing_stories_count", 0)
        
        question = (
            f"B·∫°n ƒë√£ c√≥ project '{existing_title}' v√† c√°c t√†i li·ªáu li√™n quan. "
            f"B·∫°n mu·ªën:"
        )
        
        if agent:
            await agent.message_user(
                "question",
                question,
                question_config={
                    "question_type": "multichoice",
                    "options": [
                        "Thay th·∫ø b·∫±ng project m·ªõi",
                        "Gi·ªØ nguy√™n project c≈©"
                    ],
                    "allow_multiple": False,
                    "context": {
                        "original_user_message": state.get("user_message", "")
                    }
                }
            )
        
        logger.info(f"[confirm_replace] Asked user to confirm replacing '{existing_title}'")
        
        return {
            **state,
            "action": "CONFIRM_REPLACE",
            "waiting_for_answer": True
        }
    except Exception as e:
        logger.error(f"[confirm_replace] Error: {e}", exc_info=True)
        if agent:
            await agent.message_user("response", "C√≥ l·ªói x·∫£y ra, vui l√≤ng th·ª≠ l·∫°i.")
        return {**state, "action": "RESPOND"}
