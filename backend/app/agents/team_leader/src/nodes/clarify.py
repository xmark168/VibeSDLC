"""Clarify node for Team Leader."""

import logging

from langchain_core.messages import HumanMessage, SystemMessage

from app.core.agent.llm_factory import get_llm
from app.core.agent.prompt_utils import build_system_prompt
from app.agents.team_leader.src.nodes._utils import get_callback_config, _PROMPTS, _DEFAULTS
from app.agents.team_leader.src.state import TeamLeaderState

logger = logging.getLogger(__name__)


async def clarify(state: TeamLeaderState, agent=None) -> TeamLeaderState:
    """Ask clarification question using LLM with persona."""
    try:
        reason = state.get("reason", "need more details")
        hint = state.get("clarification_question", "")

        sys_prompt = build_system_prompt(_PROMPTS, "conversational", agent, _DEFAULTS)
        user_prompt = f"""User v·ª´a n√≥i: "{state['user_message']}"

M√¨nh c·∫ßn h·ªèi clarification v√¨: {reason}
{f'G·ª£i √Ω c√¢u h·ªèi: {hint}' if hint else ''}

H√£y vi·∫øt M·ªòT c√¢u h·ªèi clarification th√¢n thi·ªán, t·ª± nhi√™n ƒë·ªÉ hi·ªÉu r√µ h∆°n user mu·ªën g√¨.
- Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao c·∫ßn th√™m info
- G·ª£i √Ω c·ª• th·ªÉ user c·∫ßn cung c·∫•p g√¨ (feature name, error message, steps...)
- D√πng emoji ph√π h·ª£p"""

        response = await get_llm("respond").ainvoke(
            [SystemMessage(content=sys_prompt), HumanMessage(content=user_prompt)],
            config=get_callback_config(state, "clarify")
        )
        question = response.content
    except Exception as e:
        logger.error(f"[clarify] LLM error: {e}")
        question = state.get("message") or "Hmm, m√¨nh c·∫ßn bi·∫øt r√µ h∆°n ch√∫t! ü§î B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n kh√¥ng?"

    if agent:
        await agent.message_user("response", question)

    return {**state, "message": question, "action": "CLARIFY"}
