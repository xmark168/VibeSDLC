#!/usr/bin/env python3
"""
Test script Ä‘á»ƒ verify sequential task overwriting fix V2
"""

import os

def test_enhanced_prompt_warnings():
    """Test that prompts have enhanced visual warnings"""
    
    print("ğŸ§ª Testing Enhanced Prompt Warnings V2")
    print("=" * 60)
    
    prompts_path = "ai-agent-service/app/agents/developer/implementor/utils/prompts.py"
    
    if not os.path.exists(prompts_path):
        print(f"âŒ File not found: {prompts_path}")
        return False
    
    try:
        with open(prompts_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Check for enhanced visual warnings
        checks = [
            ("Sequential task alert", "ğŸš¨ SEQUENTIAL TASK ALERT ğŸš¨" in content),
            ("Visual emphasis", "This file has been MODIFIED by previous tasks" in content),
            ("Critical instructions", "âš ï¸ CRITICAL INSTRUCTIONS:" in content),
            ("Numbered steps", "1. The CURRENT FILE CONTENT below is the ACTUAL state" in content),
            ("Copy-paste instruction", "4. COPY-PASTE directly from the current content below" in content),
            ("Add without removing", "5. ADD your new functionality WITHOUT removing existing code" in content),
            ("Current content emphasis", "ğŸ” CURRENT FILE CONTENT (ACTUAL FILE STATE AFTER PREVIOUS TASKS):" in content),
            ("Clear task directive", "ğŸ¯ YOUR TASK: Add new functionality while preserving ALL existing code" in content),
        ]
        
        passed = 0
        for check_name, check_result in checks:
            status = "âœ…" if check_result else "âŒ"
            print(f"   {status} {check_name}")
            if check_result:
                passed += 1
        
        print(f"\nğŸ“Š Enhanced prompt checks: {passed}/{len(checks)} passed")
        return passed == len(checks)
        
    except Exception as e:
        print(f"âŒ Error reading prompts file: {e}")
        return False

def test_sequential_task_examples():
    """Test that sequential task examples have been added"""
    
    print("\nğŸ§ª Testing Sequential Task Examples")
    print("=" * 60)
    
    prompts_path = "ai-agent-service/app/agents/developer/implementor/utils/prompts.py"
    
    try:
        with open(prompts_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        checks = [
            ("Sequential task example", "<example_sequential_task>" in content),
            ("Auth routes scenario", "Add login endpoint to existing auth routes file" in content),
            ("Register endpoint context", "router.post('/register'" in content),
            ("Export anchor OLD_CODE", "export default router;" in content),
            ("Additive NEW_CODE", "router.post('/login'" in content),
            ("Preserve existing code", "// existing register logic" in content),
        ]
        
        passed = 0
        for check_name, check_result in checks:
            status = "âœ…" if check_result else "âŒ"
            print(f"   {status} {check_name}")
            if check_result:
                passed += 1
        
        print(f"\nğŸ“Š Sequential task example checks: {passed}/{len(checks)} passed")
        return passed == len(checks)
        
    except Exception as e:
        print(f"âŒ Error reading prompts file: {e}")
        return False

def test_enhanced_context_display():
    """Test that context display has been enhanced"""
    
    print("\nğŸ§ª Testing Enhanced Context Display")
    print("=" * 60)
    
    generate_code_path = "ai-agent-service/app/agents/developer/implementor/nodes/generate_code.py"
    
    try:
        with open(generate_code_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        checks = [
            ("File analysis section", "ğŸ“‹ FILE ANALYSIS:" in content),
            ("Total lines display", "- Total lines:" in content),
            ("File size display", "- File size:" in content),
            ("Existing code confirmation", "- Contains existing code from previous tasks" in content),
            ("Add reminder", "ğŸ¯ REMEMBER: This file already has functionality. ADD to it, don't replace it!" in content),
            ("Enhanced context display", "current_content_display =" in content),
        ]
        
        passed = 0
        for check_name, check_result in checks:
            status = "âœ…" if check_result else "âŒ"
            print(f"   {status} {check_name}")
            if check_result:
                passed += 1
        
        print(f"\nğŸ“Š Enhanced context display checks: {passed}/{len(checks)} passed")
        return passed == len(checks)
        
    except Exception as e:
        print(f"âŒ Error reading generate_code file: {e}")
        return False

def test_endpoint_detection_logging():
    """Test that endpoint detection logging has been added"""
    
    print("\nğŸ§ª Testing Endpoint Detection Logging")
    print("=" * 60)
    
    generate_code_path = "ai-agent-service/app/agents/developer/implementor/nodes/generate_code.py"
    
    try:
        with open(generate_code_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        checks = [
            ("Register endpoint detection", "Register endpoint found in current content" in content),
            ("Login endpoint detection", "Login endpoint found in current content" in content),
            ("Pattern checking logic", 'if "/register" in existing_content:' in content),
            ("Debug logging format", "ğŸ” DEBUG:" in content),
        ]
        
        passed = 0
        for check_name, check_result in checks:
            status = "âœ…" if check_result else "âŒ"
            print(f"   {status} {check_name}")
            if check_result:
                passed += 1
        
        print(f"\nğŸ“Š Endpoint detection logging checks: {passed}/{len(checks)} passed")
        return passed == len(checks)
        
    except Exception as e:
        print(f"âŒ Error reading generate_code file: {e}")
        return False

def analyze_current_file_states():
    """Analyze current state cá»§a test files"""
    
    print("\nğŸ§ª Analyzing Current File States")
    print("=" * 60)
    
    files_to_check = [
        {
            "path": "ai-agent-service/app/agents/demo/be/nodejs/express-basic/src/controllers/authController.js",
            "name": "authController.js",
            "expected_patterns": ["/login"],
            "missing_patterns": ["/register"]
        },
        {
            "path": "ai-agent-service/app/agents/demo/be/nodejs/express-basic/src/models/User.js",
            "name": "User.js",
            "expected_patterns": ["const User = mongoose.model", "userSchema"],
            "missing_patterns": ["comparePassword"]
        }
    ]
    
    results = []
    
    for file_info in files_to_check:
        print(f"\nğŸ“„ Analyzing {file_info['name']}:")
        
        try:
            with open(file_info['path'], 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"   ğŸ“ Content length: {len(content)} chars")
            print(f"   ğŸ“Š Line count: {content.count(chr(10)) + 1}")
            
            # Check expected patterns
            expected_found = 0
            for pattern in file_info['expected_patterns']:
                if pattern in content:
                    print(f"   âœ… Expected pattern found: {pattern}")
                    expected_found += 1
                else:
                    print(f"   âŒ Expected pattern missing: {pattern}")
            
            # Check missing patterns (should not be there yet)
            missing_confirmed = 0
            for pattern in file_info['missing_patterns']:
                if pattern not in content:
                    print(f"   âœ… Missing pattern confirmed: {pattern} (expected to be missing)")
                    missing_confirmed += 1
                else:
                    print(f"   âš ï¸ Missing pattern found: {pattern} (unexpected)")
            
            file_ready = expected_found == len(file_info['expected_patterns'])
            results.append((file_info['name'], file_ready))
            
        except Exception as e:
            print(f"   âŒ Error reading file: {e}")
            results.append((file_info['name'], False))
    
    return results

def analyze_fix_v2_effectiveness():
    """Analyze effectiveness cá»§a V2 fix"""
    
    print("\nğŸ§ª Analyzing Fix V2 Effectiveness")
    print("=" * 60)
    
    improvements = [
        {
            "area": "Visual Impact",
            "v1": "Simple text warnings",
            "v2": "ğŸš¨ Alert system vá»›i emojis vÃ  visual cues",
            "impact": "Impossible to miss sequential task warnings",
            "status": "âœ… ENHANCED"
        },
        {
            "area": "Instructions Clarity",
            "v1": "Generic critical warnings",
            "v2": "5 numbered critical steps vá»›i specific guidance",
            "impact": "Step-by-step LLM guidance",
            "status": "âœ… ENHANCED"
        },
        {
            "area": "Examples",
            "v1": "Generic modification examples",
            "v2": "Sequential task specific example vá»›i auth routes",
            "impact": "Realistic scenario demonstration",
            "status": "âœ… ADDED"
        },
        {
            "area": "Context Display",
            "v1": "Basic current content",
            "v2": "File analysis vá»›i statistics vÃ  reminders",
            "impact": "Enhanced LLM understanding cá»§a file state",
            "status": "âœ… ENHANCED"
        },
        {
            "area": "Debug Logging",
            "v1": "Basic content logging",
            "v2": "Endpoint detection vÃ  pattern recognition",
            "impact": "Better tracking cá»§a existing functionality",
            "status": "âœ… ENHANCED"
        }
    ]
    
    for improvement in improvements:
        print(f"ğŸ”§ {improvement['area']}")
        print(f"   ğŸ“ V1: {improvement['v1']}")
        print(f"   ğŸš€ V2: {improvement['v2']}")
        print(f"   ğŸ¯ Impact: {improvement['impact']}")
        print(f"   {improvement['status']}")
        print()
    
    print("ğŸ¯ Expected V2 Results:")
    print("1. âœ… LLM receives impossible-to-miss visual alerts")
    print("2. âœ… Step-by-step guidance prevents confusion")
    print("3. âœ… Realistic examples show proper sequential task handling")
    print("4. âœ… File analysis emphasizes existing content")
    print("5. âœ… Enhanced debugging tracks functionality preservation")
    print("6. âœ… authController.js will contain BOTH register AND login")
    print("7. âœ… User.js modifications will use correct OLD_CODE")
    
    return True

def main():
    """Main test function"""
    
    print("ğŸš€ Sequential Task Overwriting Fix V2 Verification")
    print("=" * 80)
    
    tests = [
        ("Enhanced prompt warnings", test_enhanced_prompt_warnings),
        ("Sequential task examples", test_sequential_task_examples),
        ("Enhanced context display", test_enhanced_context_display),
        ("Endpoint detection logging", test_endpoint_detection_logging),
        ("Fix V2 effectiveness analysis", analyze_fix_v2_effectiveness),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ Test '{test_name}' failed: {e}")
            results.append((test_name, False))
    
    # Analyze current file states
    print("\n" + "=" * 80)
    file_states = analyze_current_file_states()
    
    # Summary
    print("\n" + "=" * 80)
    print("ğŸ“Š SEQUENTIAL TASK OVERWRITING FIX V2 SUMMARY")
    print("=" * 80)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"   {status} - {test_name}")
        if result:
            passed += 1
    
    print(f"\nTest Results: {passed}/{total} tests passed")
    
    print(f"\nFile States:")
    for file_name, ready in file_states:
        status = "âœ… READY" if ready else "âš ï¸ NEEDS ATTENTION"
        print(f"   {status} - {file_name}")
    
    if passed == total:
        print("\nğŸ‰ Sequential Task Overwriting Fix V2 Verified!")
        print("\nâœ… V2 Enhancements Applied:")
        print("   - ğŸš¨ Visual alert system vá»›i emojis")
        print("   - âš ï¸ 5 numbered critical instructions")
        print("   - ğŸ“‹ File analysis vá»›i statistics")
        print("   - ğŸ¯ Clear 'ADD, don't replace' directive")
        print("   - ğŸ” Sequential task specific examples")
        print("   - ğŸ” Enhanced endpoint detection logging")
        
        print("\nğŸš€ Expected V2 Workflow:")
        print("   1. Task receives ğŸš¨ SEQUENTIAL TASK ALERT")
        print("   2. LLM sees ğŸ“‹ FILE ANALYSIS vá»›i existing content")
        print("   3. LLM follows 5 numbered critical instructions")
        print("   4. LLM uses sequential task example as guide")
        print("   5. LLM adds new functionality WITHOUT removing existing")
        print("   6. Both register AND login endpoints preserved âœ…")
        
        print("\nğŸ“‹ Next Steps:")
        print("   - Run actual Developer Agent sequential tasks")
        print("   - Monitor enhanced debug logs")
        print("   - Verify additive behavior (no overwriting)")
        print("   - Confirm both endpoints exist after all tasks")
        
    else:
        print("âš ï¸ Some V2 verification checks failed.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
