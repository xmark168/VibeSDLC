# Langfuse Integration - Quick Start Guide

## ğŸš€ Quick Start (5 phÃºt)

### BÆ°á»›c 1: Verify Credentials

Kiá»ƒm tra file `.env` Ä‘Ã£ cÃ³ credentials:

```bash
cat .env | grep LANGFUSE
```

Káº¿t quáº£ mong Ä‘á»£i:
```
LANGFUSE_HOST=https://langfuse.vibesdlc.com
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxx
```

âœ… Náº¿u cÃ³ Ä‘áº§y Ä‘á»§ â†’ Tiáº¿p tá»¥c bÆ°á»›c 2
âŒ Náº¿u thiáº¿u â†’ ThÃªm credentials vÃ o `.env`

### BÆ°á»›c 2: Test Integration

Cháº¡y test suite:

```bash
cd services/ai-agent-service
python test_langfuse_integration.py
```

Káº¿t quáº£ mong Ä‘á»£i:
```
âœ… PASS - Client Initialization
âœ… PASS - CallbackHandler Creation
âœ… PASS - Manual Trace Span
âœ… PASS - Developer Agent Execution
âœ… PASS - Trace Visibility

Results: 5/5 tests passed
ğŸ‰ All tests passed!
```

### BÆ°á»›c 3: View Traces

1. Má»Ÿ browser: https://langfuse.vibesdlc.com
2. Login vá»›i credentials
3. Navigate to "Traces"
4. TÃ¬m trace vá»›i session ID: `test-langfuse-integration`

### BÆ°á»›c 4: Use in Your Code

```python
from app.agents.developer import run_developer

# Chá»‰ cáº§n gá»i nhÆ° bÃ¬nh thÆ°á»ng - tracing tá»± Ä‘á»™ng!
result = await run_developer(
    user_request="Add user authentication",
    working_directory="./src",
)

# Hoáº·c vá»›i custom session ID
result = await run_developer(
    user_request="Add user authentication",
    working_directory="./src",
    session_id="my-feature-123",
    user_id="developer-john",
)
```

## ğŸ“Š What Gets Traced?

### Automatic (khÃ´ng cáº§n code thÃªm)

âœ… **LLM Calls**
- Model name, input, output
- Token usage, latency
- Cost tracking

âœ… **Tool Executions**
- Tool name, parameters
- Results, timing
- Success/failure status

âœ… **Agent Steps**
- Each step in workflow
- Actions and observations
- Decision making process

âœ… **Errors**
- Error type and message
- Stack traces
- Failed operations

### Manual (optional, cho detailed tracking)

```python
from app.utils.langfuse_tracer import trace_span

with trace_span(
    name="custom_operation",
    metadata={"feature": "auth", "priority": "high"}
) as span:
    # Your code here
    result = do_something()
    
    # Optional: add output
    span.end(output={"result": result})
```

## ğŸ” Common Use Cases

### Use Case 1: Debug Failed Execution

```python
try:
    result = await run_developer(
        user_request="Complex feature",
        working_directory="./src",
        session_id="debug-session-123",
    )
except Exception as e:
    print(f"Failed: {e}")
    print("Check Langfuse for details: session_id=debug-session-123")
```

â†’ Xem trace trong Langfuse Ä‘á»ƒ biáº¿t:
- BÆ°á»›c nÃ o failed?
- Error message chi tiáº¿t
- Stack trace Ä‘áº§y Ä‘á»§
- State táº¡i thá»i Ä‘iá»ƒm lá»—i

### Use Case 2: Monitor Performance

```python
import time

start = time.time()
result = await run_developer(
    user_request="Add feature",
    working_directory="./src",
    session_id="perf-test-1",
)
print(f"Local time: {time.time() - start}s")
```

â†’ So sÃ¡nh vá»›i timing trong Langfuse:
- Tá»•ng execution time
- Time cho tá»«ng tool
- LLM latency
- Bottlenecks

### Use Case 3: Track Multiple Features

```python
features = [
    "Add user model",
    "Add user endpoints", 
    "Add user tests",
]

for i, feature in enumerate(features):
    result = await run_developer(
        user_request=feature,
        working_directory="./src",
        session_id=f"batch-{i+1}",
        user_id="developer-john",
    )
```

â†’ Filter trong Langfuse by:
- User ID: `developer-john`
- Session ID pattern: `batch-*`
- Date range

### Use Case 4: Compare Model Performance

```python
models = ["gpt-4o-mini", "gpt-4o"]

for model in models:
    result = await run_developer(
        user_request="Same task",
        working_directory="./src",
        model_name=model,
        session_id=f"model-comparison-{model}",
    )
```

â†’ Compare trong Langfuse:
- Execution time
- Token usage
- Cost
- Quality of output

## ğŸ“ˆ Dashboard Tips

### Filter Traces

```
Session ID: feature-auth-*
User ID: developer-john
Date: Last 7 days
Status: Error
```

### Analyze Metrics

1. **Execution Time**: Identify slow operations
2. **Token Usage**: Track costs
3. **Error Rate**: Monitor reliability
4. **Tool Usage**: See which tools are used most

### Create Views

Save common filters as views:
- "My Recent Executions"
- "Failed Executions"
- "Slow Executions (>60s)"
- "High Cost Executions"

## ğŸ› ï¸ Troubleshooting

### Problem: No traces appearing

**Check:**
1. âœ… Credentials in `.env`
2. âœ… Network connectivity to Langfuse host
3. âœ… Console logs for errors
4. âœ… Wait a few seconds for traces to appear

**Solution:**
```bash
# Test connection
python -c "from app.utils.langfuse_tracer import get_langfuse_client; print('OK' if get_langfuse_client() else 'FAIL')"
```

### Problem: Traces incomplete

**Possible causes:**
- Agent crashed before flush
- Network timeout
- Rate limiting

**Solution:**
```python
from app.utils.langfuse_tracer import flush_langfuse

# Manually flush at end
try:
    result = await run_developer(...)
finally:
    flush_langfuse()
```

### Problem: Too much data

**Solution:**
Disable tracing temporarily:

```bash
# In .env, comment out credentials
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
```

Agent will still work, just without tracing.

## ğŸ“š Learn More

- **Full Documentation**: `app/utils/LANGFUSE_INTEGRATION.md`
- **Examples**: `examples/langfuse_tracing_example.py`
- **Test Suite**: `test_langfuse_integration.py`
- **Summary**: `LANGFUSE_INTEGRATION_SUMMARY.md`

## ğŸ¯ Best Practices

### DO âœ…

- Use meaningful session IDs: `feature-auth-2024-01-15`
- Add metadata for context: `{"priority": "high", "team": "backend"}`
- Check traces after errors
- Monitor execution times
- Track costs

### DON'T âŒ

- Don't use random session IDs: `abc123`
- Don't ignore error traces
- Don't forget to flush in long-running processes
- Don't log sensitive data in metadata

## ğŸš¦ Status Indicators

### Console Output

```
âœ… Langfuse client initialized successfully
âœ… Langfuse tracing enabled for session: my-session
ğŸ“Š Langfuse tracing: Session my-session
ğŸš€ Starting developer agent execution...
âœ… Developer agent execution completed in 45.67s
âœ… Langfuse traces flushed successfully
```

### What They Mean

- âœ… Green checkmark: Success
- âš ï¸ Warning triangle: Non-critical issue
- âŒ Red X: Error
- ğŸ“Š Chart: Tracing info
- ğŸš€ Rocket: Starting operation

## ğŸ’¡ Pro Tips

1. **Use consistent naming**: `feature-{name}-{date}`
2. **Add user context**: Always set `user_id` for team tracking
3. **Review daily**: Check traces at end of day
4. **Set up alerts**: For errors and slow executions
5. **Share traces**: Use session IDs to share with team

## âœ¨ That's It!

Báº¡n Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng Langfuse tracing!

**Next steps:**
1. âœ… Run test suite
2. âœ… Try basic example
3. âœ… Check dashboard
4. âœ… Use in your development workflow

**Questions?**
- Check documentation in `app/utils/LANGFUSE_INTEGRATION.md`
- Run examples in `examples/langfuse_tracing_example.py`
- Review test suite in `test_langfuse_integration.py`

Happy tracing! ğŸ‰

