import json
import os
import re
from typing import Any, Literal

from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langfuse.langchain import CallbackHandler
from langgraph.graph import END, START, StateGraph
from pydantic import BaseModel, Field

from app.templates.prompts.product_owner.vision import (
    GENERATE_PROMPT,
    VALIDATE_PROMPT,
    REASON_PROMPT,
    FINALIZE_PROMPT,
)

from langgraph.checkpoint.memory import MemorySaver

load_dotenv()


class AudienceSegment(BaseModel):
    name: str = Field(description="T√™n nh√≥m ƒë·ªëi t∆∞·ª£ng")
    description: str = Field(description="M√¥ t·∫£ nh√≥m ƒë·ªëi t∆∞·ª£ng")
    needs: list[str] = Field(description="Nhu c·∫ßu c·ªßa nh√≥m")
    pain_points: list[str] = Field(description="ƒêi·ªÉm ƒëau c·ªßa nh√≥m")


class FeatureRequirement(BaseModel):
    name: str = Field(description="T√™n t√≠nh nƒÉng")
    description: str = Field(description="M√¥ t·∫£ chi ti·∫øt t√≠nh nƒÉng")
    priority: str = Field(description="ƒê·ªô ∆∞u ti√™n: High, Medium, Low")
    user_stories: list[str] = Field(
        description="Danh s√°ch user stories cho t√≠nh nƒÉng n√†y"
    )
    acceptance_criteria: list[str] = Field(
        description="Ti√™u ch√≠ ch·∫•p nh·∫≠n - ƒëi·ªÅu ki·ªán c·ª• th·ªÉ ƒë·ªÉ t√≠nh nƒÉng ƒë∆∞·ª£c coi l√† ho√†n th√†nh ƒë√∫ng y√™u c·∫ßu nghi·ªáp v·ª•"
    )


class FinalizeOutput(BaseModel):
    product_name: str = Field(description="T√™n s·∫£n ph·∫©m")
    vision_statement: str = Field(description="Vision statement cu·ªëi c√πng")


class ValidateOutput(BaseModel):
    is_valid: bool = Field(description="True n·∫øu vision h·ª£p l·ªá")
    quality_score: float = Field(description="ƒêi·ªÉm ch·∫•t l∆∞·ª£ng 0.0-1.0", ge=0.0, le=1.0)
    issues: list[str] = Field(description="Danh s√°ch v·∫•n ƒë·ªÅ c·∫ßn s·ª≠a")
    validation_message: str = Field(description="Th√¥ng ƒëi·ªáp t√≥m t·∫Øt k·∫øt qu·∫£ validation")


class GenerateOutput(BaseModel):
    draft_vision_statement: str = Field(description="Tuy√™n b·ªë t·∫ßm nh√¨n (solution-free)")
    experience_principles: list[str] = Field(description="3-5 nguy√™n t·∫Øc tr·∫£i nghi·ªám")
    problem_summary: str = Field(description="T√≥m t·∫Øt v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt")
    audience_segments: list[AudienceSegment] = Field(
        description="Ph√¢n t√≠ch c√°c nh√≥m ƒë·ªëi t∆∞·ª£ng"
    )
    scope_capabilities: list[str] = Field(
        description="Kh·∫£ nƒÉng c·ªët l√µi (kh√¥ng ph·∫£i t√≠nh nƒÉng)"
    )
    scope_non_goals: list[str] = Field(
        description="Nh·ªØng g√¨ KH√îNG l√†m trong phi√™n b·∫£n n√†y"
    )

    # PRD: Functional Requirements
    functional_requirements: list[FeatureRequirement] = Field(
        description="C√°c t√≠nh nƒÉng c·ª• th·ªÉ c·∫ßn implement"
    )

    # PRD: Non-Functional Requirements
    performance_requirements: list[str] = Field(description="Y√™u c·∫ßu v·ªÅ hi·ªáu nƒÉng")
    security_requirements: list[str] = Field(description="Y√™u c·∫ßu v·ªÅ b·∫£o m·∫≠t")
    ux_requirements: list[str] = Field(description="Y√™u c·∫ßu v·ªÅ tr·∫£i nghi·ªám ng∆∞·ªùi d√πng")

    dependencies: list[str] = Field(description="C√°c ph·ª• thu·ªôc k·ªπ thu·∫≠t")
    risks: list[str] = Field(description="C√°c r·ªßi ro ti·ªÅm ·∫©n")
    assumptions: list[str] = Field(description="C√°c gi·∫£ ƒë·ªãnh quan tr·ªçng")


class VisionState(BaseModel):
    # Input & Messages
    messages: list[BaseMessage] = Field(default_factory=list)
    product_brief: dict = Field(default_factory=dict)

    # Draft components from generate node
    draft_vision_statement: str = ""
    experience_principles: list[str] = Field(default_factory=list)
    problem_summary: str = ""
    audience_segments: list[dict] = Field(default_factory=list)
    scope_capabilities: list[str] = Field(default_factory=list)
    scope_non_goals: list[str] = Field(default_factory=list)

    # PRD components
    functional_requirements: list[dict] = Field(default_factory=list)
    performance_requirements: list[str] = Field(default_factory=list)
    security_requirements: list[str] = Field(default_factory=list)
    ux_requirements: list[str] = Field(default_factory=list)

    dependencies: list[str] = Field(default_factory=list)
    risks: list[str] = Field(default_factory=list)
    assumptions: list[str] = Field(default_factory=list)

    # Validation
    quality_score: float = 0.0
    validation_result: str = ""

    # User interaction
    user_choice: Literal["approve", "edit", ""] = ""
    edit_reason: str = ""

    # Final output
    product_vision: dict = Field(default_factory=dict)
    status: str = "initial"


class VisionAgent:

    def __init__(
        self,
        session_id: str | None = None,
        user_id: str | None = None,
        websocket_broadcast_fn=None,
        project_id: str | None = None,
        response_manager=None,
        event_loop=None
    ):
        """Kh·ªüi t·∫°o vision agent.

        Args:
            session_id: Session ID t√πy ch·ªçn ƒë·ªÉ theo d√µi
            user_id: User ID t√πy ch·ªçn ƒë·ªÉ theo d√µi
            websocket_broadcast_fn: Async function to broadcast WebSocket messages (optional)
            project_id: Project ID for WebSocket broadcasting (optional)
            response_manager: ResponseManager for human-in-the-loop via WebSocket (optional)
            event_loop: Event loop for async operations (required for WebSocket mode)
        """
        self.session_id = session_id
        self.user_id = user_id

        # WebSocket dependencies (optional)
        self.websocket_broadcast_fn = websocket_broadcast_fn
        self.project_id = project_id
        self.response_manager = response_manager
        self.event_loop = event_loop
        self.use_websocket = (
            websocket_broadcast_fn is not None
            and project_id is not None
            and response_manager is not None
        )

        # Initialize Langfuse callback handler (without session_id/user_id in constructor)
        # Session/user metadata will be passed via config metadata during invoke/stream
        self.langfuse_handler = CallbackHandler()

        self.graph = self._build_graph()

    def _llm(self, model: str, temperature: str) -> ChatOpenAI:
        try:
            llm = ChatOpenAI(
                model=model,
                temperature=temperature,
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url=os.getenv("OPENAI_BASE_URL"),
            )
            return llm
        except Exception:
            return ""

    def _build_graph(self) -> StateGraph:
        graph_builder = StateGraph(VisionState)

        graph_builder.add_node("initialize", self.initialize)
        graph_builder.add_node("generate", self.generate)
        graph_builder.add_node("validate", self.validate)
        # Use async versions for preview and reason (supports both WebSocket and terminal modes)
        graph_builder.add_node("preview", self.preview_async)
        graph_builder.add_node("reason", self.reason_async)
        graph_builder.add_node("finalize", self.finalize)

        graph_builder.add_edge(START, "initialize")
        graph_builder.add_edge("initialize", "generate")
        graph_builder.add_edge("generate", "validate")
        graph_builder.add_edge("validate", "preview")
        graph_builder.add_conditional_edges("preview", self.preview_branch)
        graph_builder.add_edge("reason", "generate")  # Loop back to generate
        graph_builder.add_edge("finalize", END)

        checkpointer = MemorySaver()

        return graph_builder.compile(checkpointer=checkpointer)

    def initialize(self, state: VisionState) -> VisionState:
        """Initialize - Load schema (ProductVision) v√† load product_brief (chu·∫©n b·ªã d·ªØ li·ªáu).

        Theo s∆° ƒë·ªì:
        - Load schema ProductVision ƒë·ªÉ validate structure
        - Load product_brief t·ª´ state (ƒë√£ c√≥ s·∫µn)
        - Chu·∫©n b·ªã d·ªØ li·ªáu cho c√°c node ti·∫øp theo
        """
        print("\n" + "=" * 80)
        print("üöÄ INITIALIZE - KH·ªûI T·∫†O VISION AGENT")
        print("=" * 80)

        # Validate product_brief structure (ƒë√£ c√≥ trong state.product_brief)
        if not state.product_brief or len(state.product_brief) == 0:
            print("‚ö† Ch∆∞a c√≥ product_brief, s·∫Ω c·∫ßn th√¥ng tin b·ªï sung")
            state.status = "missing_brief"
        else:
            print(f"‚úì ƒê√£ load product_brief t·ª´ state")
            print(f"  - Product Name: {state.product_brief.get('product_name', 'N/A')}")
            print(
                f"  - Description: {state.product_brief.get('description', 'N/A')[:100]}..."
            )

            required_fields = [
                "product_name",
                "description",
                "target_audience",
                "key_features",
            ]
            missing_fields = [
                field for field in required_fields if field not in state.product_brief
            ]

            if missing_fields:
                print(f"‚ö† Product brief thi·∫øu c√°c tr∆∞·ªùng: {', '.join(missing_fields)}")
                state.status = "incomplete_brief"
            else:
                print("‚úì Product brief ƒë·∫ßy ƒë·ªß c√°c tr∆∞·ªùng b·∫Øt bu·ªôc")
                state.status = "ready"

        print("=" * 80 + "\n")

        return state

    def generate(self, state: VisionState) -> VisionState:
        """Generate - T·∫°o draft vision statement, experience principles v√† ƒëi·ªÅn c√°c th√¥ng tin.

        Theo s∆° ƒë·ªì:
        - Draft vision statement (solution-free)
        - 3-5 experience principles
        - ƒêi·ªÅn: problem / audience / scope / deps / uncertainties (risks/assumptions)
        """
        print("\n" + "=" * 80)
        print("‚ú® GENERATE - T·∫†O PRODUCT VISION")
        print("=" * 80)

        # Format product brief
        brief_text = json.dumps(state.product_brief, ensure_ascii=False, indent=2)

        # Check if there's edit feedback
        if state.edit_reason:
            prompt = (
                GENERATE_PROMPT.format(brief=brief_text)
                + f"\n\n**EDIT FEEDBACK t·ª´ user:**\n{state.edit_reason}\n\nH√£y t·∫°o l·∫°i Product Vision v·ªõi nh·ªØng ƒëi·ªÅu ch·ªânh theo feedback tr√™n."
            )
        else:
            prompt = GENERATE_PROMPT.format(brief=brief_text)

        try:
            # Use structured output with Pydantic model
            structured_llm = self._llm("gpt-4o", 0.3).with_structured_output(
                GenerateOutput
            )
            generate_result = structured_llm.invoke([HumanMessage(content=prompt)])

            # Update state with generated components
            state.draft_vision_statement = generate_result.draft_vision_statement
            state.experience_principles = generate_result.experience_principles
            state.problem_summary = generate_result.problem_summary
            state.audience_segments = [
                seg.model_dump() for seg in generate_result.audience_segments
            ]
            state.scope_capabilities = generate_result.scope_capabilities
            state.scope_non_goals = generate_result.scope_non_goals

            # PRD components
            state.functional_requirements = [
                req.model_dump() for req in generate_result.functional_requirements
            ]
            state.performance_requirements = generate_result.performance_requirements
            state.security_requirements = generate_result.security_requirements
            state.ux_requirements = generate_result.ux_requirements

            state.dependencies = generate_result.dependencies
            state.risks = generate_result.risks
            state.assumptions = generate_result.assumptions

            # Print summary
            print(f"\n‚úì ƒê√£ t·∫°o Product Vision draft")
            print(f"\nüìù Vision Statement:")
            print(f"   {state.draft_vision_statement}")
            print(f"\nüí° Experience Principles ({len(state.experience_principles)}):")
            for i, principle in enumerate(state.experience_principles, 1):
                print(f"   {i}. {principle}")
            print(f"\nüéØ Problem: {state.problem_summary[:100]}...")
            print(f"üë• Audience Segments: {len(state.audience_segments)}")
            print(f"‚öôÔ∏è  Capabilities: {len(state.scope_capabilities)}")
            print(f"üö´ Non-Goals: {len(state.scope_non_goals)}")
            print(
                f"\nüìã PRD - Functional Requirements: {len(state.functional_requirements)}"
            )
            print(f"‚ö° Performance Requirements: {len(state.performance_requirements)}")
            print(f"üîí Security Requirements: {len(state.security_requirements)}")
            print(f"üé® UX Requirements: {len(state.ux_requirements)}")
            print(f"\nüîó Dependencies: {len(state.dependencies)}")
            print(f"‚ö†Ô∏è  Risks: {len(state.risks)}")
            print(f"üí≠ Assumptions: {len(state.assumptions)}")

            print("\n" + "=" * 80 + "\n")

            # Print structured output
            print("\nüìä Structured Output t·ª´ generate:")
            print(
                json.dumps(generate_result.model_dump(), ensure_ascii=False, indent=2)
            )
            print()

        except Exception as e:
            print(f"‚ùå L·ªói khi generate vision: {e}")
            import traceback

            traceback.print_exc()
            state.status = "error_generating"

        # Consolidate to product_vision dict for easy access
        state.product_vision = {
            "draft_vision_statement": state.draft_vision_statement,
            "experience_principles": state.experience_principles,
            "problem_summary": state.problem_summary,
            "audience_segments": state.audience_segments,
            "scope_capabilities": state.scope_capabilities,
            "scope_non_goals": state.scope_non_goals,
            "functional_requirements": state.functional_requirements,
            "performance_requirements": state.performance_requirements,
            "security_requirements": state.security_requirements,
            "ux_requirements": state.ux_requirements,
            "dependencies": state.dependencies,
            "risks": state.risks,
            "assumptions": state.assumptions,
        }

        return state

    def validate(self, state: VisionState) -> VisionState:
        """Validate - Ki·ªÉm tra clarity, inspiration, solution-free, schema & completeness.

        Theo s∆° ƒë·ªì:
        - Ki·ªÉm tra vision statement: clarity & inspiration
        - Ki·ªÉm tra solution-free (kh√¥ng n√≥i v·ªÅ c√¥ng ngh·ªá c·ª• th·ªÉ)
        - Ki·ªÉm tra schema & completeness
        - T√≠nh quality_score
        """
        print("\n" + "=" * 80)
        print("‚úÖ VALIDATE - KI·ªÇM TRA PRODUCT VISION")
        print("=" * 80)

        # Prepare vision draft for validation
        vision_draft = {
            "draft_vision_statement": state.draft_vision_statement,
            "experience_principles": state.experience_principles,
            "problem_summary": state.problem_summary,
            "audience_segments": state.audience_segments,
            "scope_capabilities": state.scope_capabilities,
            "scope_non_goals": state.scope_non_goals,
            "functional_requirements": state.functional_requirements,
            "performance_requirements": state.performance_requirements,
            "security_requirements": state.security_requirements,
            "ux_requirements": state.ux_requirements,
            "dependencies": state.dependencies,
            "risks": state.risks,
            "assumptions": state.assumptions,
        }

        vision_text = json.dumps(vision_draft, ensure_ascii=False, indent=2)
        prompt = VALIDATE_PROMPT.format(vision_draft=vision_text)

        try:
            # Use structured output with Pydantic model
            structured_llm = self._llm("gpt-4o", 0.1).with_structured_output(
                ValidateOutput
            )
            validate_result = structured_llm.invoke([HumanMessage(content=prompt)])

            # Update state
            state.quality_score = validate_result.quality_score
            state.validation_result = validate_result.validation_message

            # Print validation result
            print(f"\n‚úì Validation completed")
            print(f"   Valid: {'‚úÖ Yes' if validate_result.is_valid else '‚ùå No'}")
            print(f"   Quality Score: {validate_result.quality_score:.2f}")
            print(f"   Message: {validate_result.validation_message}")

            if validate_result.issues:
                print(f"\n‚ö†Ô∏è  Issues found ({len(validate_result.issues)}):")
                for i, issue in enumerate(validate_result.issues, 1):
                    print(f"   {i}. {issue}")

            print("\n" + "=" * 80 + "\n")

            # Print structured output
            print("\nüìä Structured Output t·ª´ validate:")
            print(
                json.dumps(validate_result.model_dump(), ensure_ascii=False, indent=2)
            )
            print()

        except Exception as e:
            print(f"‚ùå L·ªói khi validate vision: {e}")
            import traceback

            traceback.print_exc()
            # Set low quality score on error
            state.quality_score = 0.5
            state.validation_result = f"Error during validation: {str(e)}"

        # Update product_vision with validation info
        if state.product_vision:
            state.product_vision["quality_score"] = state.quality_score
            state.product_vision["validation_result"] = state.validation_result

        return state

    async def preview_async(self, state: VisionState) -> VisionState:
        """Async version of preview - works for both WebSocket and terminal modes."""
        import uuid
        import asyncio

        print("\n[preview_async] ===== ENTERED =====", flush=True)
        print(f"[preview_async] use_websocket: {self.use_websocket}", flush=True)

        if not self.use_websocket:
            # Terminal mode - run sync version in executor
            print(f"[preview_async] Routing to terminal mode (via executor)", flush=True)
            loop = asyncio.get_running_loop()
            return await loop.run_in_executor(None, self.preview, state)

        # WebSocket mode
        print(f"[preview_async] WebSocket mode, queuing preview...", flush=True)

        # Generate unique preview ID
        preview_id = str(uuid.uuid4())

        # Queue preview message for broadcast
        preview_message = {
            "type": "agent_preview",
            "preview_id": preview_id,
            "agent": "Vision Agent",
            "preview_type": "product_vision",
            "title": "üìã PREVIEW - Product Vision & PRD",
            "vision": state.product_vision,
            "quality_score": state.quality_score,
            "validation_result": state.validation_result,
            "options": ["approve", "edit"],
            "prompt": "B·∫°n mu·ªën l√†m g√¨ v·ªõi Product Vision n√†y?"
        }

        await self.response_manager.queue_broadcast(preview_message, self.project_id)
        print(f"[preview_async] ‚úì Preview queued!", flush=True)

        # Wait for user choice
        print(f"[preview_async] Waiting for user choice...", flush=True)
        user_response = await self.response_manager.await_response(
            self.project_id,
            preview_id,
            timeout=600.0
        )

        if user_response is None:
            print(f"[preview_async] ‚è∞ Timeout, defaulting to 'approve'", flush=True)
            state.user_choice = "approve"
            return state

        # Parse user response
        if isinstance(user_response, dict):
            choice = user_response.get("choice", "approve")
            edit_reason = user_response.get("edit_changes", "")
        else:
            choice = str(user_response).strip().lower()
            edit_reason = ""

        print(f"[preview_async] User choice: {choice}", flush=True)

        state.user_choice = choice

        if choice == "edit" and edit_reason:
            state.edit_reason = edit_reason
            print(f"[preview_async] Edit reason: {edit_reason[:100]}...", flush=True)
            # Add to messages for context
            state.messages.append(HumanMessage(content=f"Edit request: {edit_reason}"))

        return state

    async def reason_async(self, state: VisionState) -> VisionState:
        """Async version of reason - collects edit reason from user via WebSocket or terminal."""
        import uuid
        import asyncio

        print("\n[reason_async] ===== ENTERED =====", flush=True)
        print(f"[reason_async] use_websocket: {self.use_websocket}", flush=True)

        if not self.use_websocket:
            # Terminal mode - run sync version in executor
            print(f"[reason_async] Routing to terminal mode (via executor)", flush=True)
            loop = asyncio.get_running_loop()
            return await loop.run_in_executor(None, self.reason, state)

        # WebSocket mode
        print(f"[reason_async] WebSocket mode, queuing question for edit reason...", flush=True)

        # Generate unique question ID
        question_id = str(uuid.uuid4())

        # Queue question for edit reason
        question_message = {
            "type": "agent_question",
            "question_id": question_id,
            "agent": "Vision Agent",
            "question_type": "text",
            "question_text": "M√¥ t·∫£ nh·ªØng ƒëi·ªÉm b·∫°n mu·ªën ch·ªânh s·ª≠a trong Product Vision. V√≠ d·ª•: Vision statement ch∆∞a ƒë·ªß inspiring, Thi·∫øu functional requirement v·ªÅ authentication, etc.",
            "timeout": 600,
            "context": "Edit Request"
        }

        await self.response_manager.queue_broadcast(question_message, self.project_id)
        print(f"[reason_async] ‚úì Question queued!", flush=True)

        # Wait for user response
        print(f"[reason_async] Waiting for edit reason...", flush=True)
        edit_reason = await self.response_manager.await_response(
            self.project_id,
            question_id,
            timeout=600.0
        )

        if edit_reason is None or not str(edit_reason).strip():
            print(f"[reason_async] ‚è∞ Timeout or empty reason, using default", flush=True)
            edit_reason = "User requested edits without specific reason"

        state.edit_reason = str(edit_reason).strip()
        print(f"[reason_async] ‚úì Edit reason received: {state.edit_reason[:100]}...", flush=True)

        # Add to messages for context
        state.messages.append(HumanMessage(content=f"Edit request: {state.edit_reason}"))

        return state

    def preview(self, state: VisionState) -> VisionState:
        """Preview - Hi·ªÉn th·ªã product vision cho user v√† h·ªèi: Approve / Edit.

        Theo s∆° ƒë·ªì:
        - Show ƒë·∫ßy ƒë·ªß vision cho user
        - H·ªèi user l·ª±a ch·ªçn: Approve ho·∫∑c Edit
        - C·∫≠p nh·∫≠t user_choice v√†o state
        """
        print("\n" + "=" * 80)
        print("üìã PREVIEW - XEM TR∆Ø·ªöC PRODUCT VISION & PRD")
        print("=" * 80)
        print(f"üéØ Quality Score: {state.quality_score:.2f}")
        print(f"üìù Validation: {state.validation_result}")
        print("=" * 80)

        # Display Vision
        print("\nüåü VISION STATEMENT:")
        print(f"   {state.draft_vision_statement}")

        print("\nüí° EXPERIENCE PRINCIPLES:")
        for i, principle in enumerate(state.experience_principles, 1):
            print(f"   {i}. {principle}")

        print(f"\nüéØ PROBLEM SUMMARY:")
        print(f"   {state.problem_summary}")

        print(f"\nüë• AUDIENCE SEGMENTS ({len(state.audience_segments)}):")
        for i, seg in enumerate(state.audience_segments, 1):
            print(
                f"   {i}. {seg.get('name', 'N/A')}: {seg.get('description', 'N/A')[:80]}..."
            )

        print(f"\n‚öôÔ∏è  SCOPE - CAPABILITIES ({len(state.scope_capabilities)}):")
        for i, cap in enumerate(state.scope_capabilities[:3], 1):  # Show first 3
            print(f"   {i}. {cap[:80]}...")
        if len(state.scope_capabilities) > 3:
            print(f"   ... v√† {len(state.scope_capabilities) - 3} kh·∫£ nƒÉng kh√°c")

        print(f"\nüö´ SCOPE - NON-GOALS ({len(state.scope_non_goals)}):")
        for i, ng in enumerate(state.scope_non_goals[:3], 1):
            print(f"   {i}. {ng[:80]}...")
        if len(state.scope_non_goals) > 3:
            print(f"   ... v√† {len(state.scope_non_goals) - 3} non-goals kh√°c")

        print(f"\nüìã FUNCTIONAL REQUIREMENTS ({len(state.functional_requirements)}):")
        for i, req in enumerate(state.functional_requirements[:3], 1):
            print(f"   {i}. {req.get('name', 'N/A')} ({req.get('priority', 'N/A')})")
        if len(state.functional_requirements) > 3:
            print(
                f"   ... v√† {len(state.functional_requirements) - 3} requirements kh√°c"
            )

        print(f"\n‚ö° PERFORMANCE REQUIREMENTS: {len(state.performance_requirements)}")
        print(f"üîí SECURITY REQUIREMENTS: {len(state.security_requirements)}")
        print(f"üé® UX REQUIREMENTS: {len(state.ux_requirements)}")

        print(f"\nüîó DEPENDENCIES: {len(state.dependencies)}")
        print(f"‚ö†Ô∏è  RISKS: {len(state.risks)}")
        print(f"üí≠ ASSUMPTIONS: {len(state.assumptions)}")

        print("\n" + "=" * 80)
        print("üí° B·∫°n c√≥ th·ªÉ:")
        print("  1. G√µ 'approve' ƒë·ªÉ ph√™ duy·ªát vision")
        print("  2. G√µ 'edit' ƒë·ªÉ ch·ªânh s·ª≠a vision")
        print("=" * 80 + "\n")

        try:
            user_choice = input("üë§ L·ª±a ch·ªçn c·ªßa b·∫°n (approve/edit): ").strip().lower()

            if user_choice not in ["approve", "edit"]:
                print(
                    f"‚ö†Ô∏è  L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá: '{user_choice}'. M·∫∑c ƒë·ªãnh ch·ªçn 'approve'."
                )
                user_choice = "approve"

            state.user_choice = user_choice

            if user_choice == "approve":
                print("‚úÖ B·∫°n ƒë√£ ph√™ duy·ªát vision.")
            elif user_choice == "edit":
                print("üìù Chuy·ªÉn sang ch·∫ø ƒë·ªô ch·ªânh s·ª≠a...")

        except Exception as e:
            print(f"‚ùå L·ªói khi nh·∫≠n input: {e}. M·∫∑c ƒë·ªãnh ch·ªçn 'approve'.")
            state.user_choice = "approve"

        return state

    def reason(self, state: VisionState) -> VisionState:
        """Reason - Thu th·∫≠p l√Ω do ch·ªânh s·ª≠a t·ª´ user.

        Theo s∆° ƒë·ªì:
        - User nh·∫≠p l√Ω do ch·ªânh s·ª≠a
        - L∆∞u edit_reason v√†o state
        - Sau ƒë√≥ quay l·∫°i generate ƒë·ªÉ t·∫°o l·∫°i v·ªõi feedback
        """
        print("\n" + "=" * 80)
        print("üìù REASON - THU TH·∫¨P L√ù DO CH·ªàNH S·ª¨A")
        print("=" * 80)
        print("üí° H√£y m√¥ t·∫£ nh·ªØng ƒëi·ªÉm b·∫°n mu·ªën ch·ªânh s·ª≠a trong Product Vision.")
        print("   V√≠ d·ª•:")
        print("   - Vision statement ch∆∞a ƒë·ªß inspiring")
        print("   - Thi·∫øu functional requirement v·ªÅ authentication")
        print("   - Performance requirement c·∫ßn c·ª• th·ªÉ h∆°n")
        print("=" * 80 + "\n")

        try:
            edit_reason = input("üë§ L√Ω do ch·ªânh s·ª≠a c·ªßa b·∫°n: ").strip()

            if not edit_reason:
                print("‚ö†Ô∏è  Kh√¥ng nh·∫≠n ƒë∆∞·ª£c l√Ω do ch·ªânh s·ª≠a. S·ª≠ d·ª•ng l√Ω do m·∫∑c ƒë·ªãnh.")
                edit_reason = "User requested edits without specific reason"

            state.edit_reason = edit_reason
            print(f"\n‚úì ƒê√£ ghi nh·∫≠n: {edit_reason}")

            # Add to messages for context
            state.messages.append(HumanMessage(content=f"Edit request: {edit_reason}"))

            # Create structured output for logging
            reason_output = {
                "edit_reason": edit_reason,
                "timestamp": "current",
                "will_regenerate": True,
            }

            print("\nüìä Structured Output t·ª´ reason:")
            print(json.dumps(reason_output, ensure_ascii=False, indent=2))
            print()

            print("üîÑ S·∫Ω t·∫°o l·∫°i Product Vision v·ªõi feedback c·ªßa b·∫°n...")

        except Exception as e:
            print(f"‚ùå L·ªói khi thu th·∫≠p l√Ω do: {e}")
            state.edit_reason = "Error collecting edit reason"

        return state

    def preview_branch(self, state: VisionState) -> str:
        """Quy·∫øt ƒë·ªãnh lu·ªìng sau preview node.

        Theo s∆° ƒë·ªì:
        - N·∫øu user ch·ªçn "approve" ‚Üí finalize
        - N·∫øu user ch·ªçn "edit" V√Ä ƒë√£ c√≥ edit_reason (t·ª´ WebSocket) ‚Üí generate (skip reason)
        - N·∫øu user ch·ªçn "edit" NH∆ØNG ch∆∞a c√≥ edit_reason (terminal mode) ‚Üí reason
        """
        if state.user_choice == "approve":
            return "finalize"
        elif state.user_choice == "edit":
            # If edit_reason already provided (WebSocket mode), skip reason node
            if state.edit_reason:
                print(f"[preview_branch] Edit reason already provided, going directly to generate", flush=True)
                return "generate"
            else:
                # Terminal mode: need to collect reason via reason node
                print(f"[preview_branch] No edit reason yet, going to reason node", flush=True)
                return "reason"
        else:
            # Default: finalize
            return "finalize"

    def finalize(self, state: VisionState) -> VisionState:
        """Finalize - L∆∞u product_vision.json v√† generate summary.md v·ªõi structured output.

        Theo s∆° ƒë·ªì:
        - L∆∞u product_vision.json
        - Generate summary.md (markdown format)
        - Update status = "completed"
        """
        print("\n" + "=" * 80)
        print("‚úÖ FINALIZE - HO√ÄN T·∫§T PRODUCT VISION & PRD")
        print("=" * 80)

        # Prepare vision for finalization
        vision_text = json.dumps(state.product_vision, ensure_ascii=False, indent=2)
        prompt = FINALIZE_PROMPT.format(vision=vision_text)

        try:
            # Use structured output with Pydantic model
            structured_llm = self._llm("gpt-4o", 0.3).with_structured_output(
                FinalizeOutput
            )
            finalize_result = structured_llm.invoke([HumanMessage(content=prompt)])

            # Update state
            state.status = "completed"

            # Update product_vision with final info
            state.product_vision["product_name"] = finalize_result.product_name
            state.product_vision["vision_statement_final"] = (
                finalize_result.vision_statement
            )

            # Print final output
            print(f"\n‚úì Finalize completed")
            print(f"   Product Name: {finalize_result.product_name}")
            print(f"   Vision Statement: {finalize_result.vision_statement}")
            print(f"   Status: {state.status}")

            print("\nüìä Structured Output t·ª´ finalize:")
            print(
                json.dumps(finalize_result.model_dump(), ensure_ascii=False, indent=2)
            )
            print()

            # Print final product_vision JSON
            print("\nüíæ FINAL PRODUCT VISION JSON:")
            print(json.dumps(state.product_vision, ensure_ascii=False, indent=2))
            print()

        except Exception as e:
            print(f"‚ùå L·ªói khi finalize vision: {e}")
            import traceback

            traceback.print_exc()
            state.status = "error_finalizing"

        print("\n" + "=" * 80)
        print(f"‚úÖ HO√ÄN T·∫§T - Status: {state.status}")
        print("=" * 80 + "\n")

        return state

    async def run_async(self, product_brief: dict, thread_id: str | None = None) -> dict[str, Any]:
        """Async version - Ch·∫°y quy tr√¨nh l√†m vi·ªác c·ªßa vision agent v·ªõi WebSocket support.

        Args:
            product_brief: Product brief t·ª´ gatherer_agent (dict ch·ª©a product info)
            thread_id: ID ƒë·ªÉ resume state (n·∫øu None, d√πng session_id ho·∫∑c default)

        Returns:
            dict: Tr·∫°ng th√°i cu·ªëi c√πng ch·ª©a product_vision v√† summary
        """
        if thread_id is None:
            thread_id = self.session_id or "default_vision_thread"

        initial_state = VisionState(
            product_brief=product_brief
        )

        # Build metadata for Langfuse tracing with session_id and user_id
        metadata = {}
        if self.session_id:
            metadata["langfuse_session_id"] = self.session_id
        if self.user_id:
            metadata["langfuse_user_id"] = self.user_id
        # Add tags
        metadata["langfuse_tags"] = ["vision_agent"]

        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": [self.langfuse_handler],
            "metadata": metadata,  # Pass session_id/user_id via metadata
            "recursion_limit": 50
        }

        final_state = None
        async for output in self.graph.astream(  # Use async version!
            initial_state.model_dump(),
            config=config,
        ):
            final_state = output

        # Convert messages to serializable format before returning
        if final_state:
            # Extract the actual state from the output (it's wrapped in a node key)
            for node_name, state_data in final_state.items():
                if isinstance(state_data, dict) and "messages" in state_data:
                    # Convert BaseMessage objects to dicts
                    serializable_messages = []
                    for msg in state_data.get("messages", []):
                        if hasattr(msg, "dict"):  # Pydantic v1
                            serializable_messages.append(msg.dict())
                        elif hasattr(msg, "model_dump"):  # Pydantic v2
                            serializable_messages.append(msg.model_dump())
                        else:
                            # Fallback for plain objects
                            serializable_messages.append({
                                "type": msg.__class__.__name__,
                                "content": str(msg.content) if hasattr(msg, "content") else str(msg)
                            })
                    state_data["messages"] = serializable_messages

        return final_state or {}

    async def run_async(self, product_brief: dict, thread_id: str | None = None) -> dict[str, Any]:
        """Async version - Ch·∫°y quy tr√¨nh l√†m vi·ªác c·ªßa vision agent.

        Args:
            product_brief: Product brief t·ª´ gatherer_agent (dict ch·ª©a product info)
            thread_id: ID ƒë·ªÉ resume state (n·∫øu None, d√πng session_id ho·∫∑c default)

        Returns:
            dict: Tr·∫°ng th√°i cu·ªëi c√πng ch·ª©a product_vision v√† summary
        """
        import asyncio

        if thread_id is None:
            thread_id = self.session_id or "default_vision_thread"

        initial_state = VisionState(product_brief=product_brief)

        # Build metadata for Langfuse tracing with session_id and user_id
        metadata = {}
        if self.session_id:
            metadata["langfuse_session_id"] = self.session_id
        if self.user_id:
            metadata["langfuse_user_id"] = self.user_id
        # Add tags
        metadata["langfuse_tags"] = ["vision_agent"]

        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": [self.langfuse_handler],
            "metadata": metadata,  # Pass session_id/user_id via metadata
            "recursion_limit": 50,
        }

        final_state = None
        async for output in self.graph.astream(
            initial_state.model_dump(),
            config=config,
        ):
            final_state = output

        # Convert messages to serializable format before returning
        if final_state:
            # Extract the actual state from the output (it's wrapped in a node key)
            for node_name, state_data in final_state.items():
                if isinstance(state_data, dict) and "messages" in state_data:
                    # Convert BaseMessage objects to dicts
                    serializable_messages = []
                    for msg in state_data.get("messages", []):
                        if hasattr(msg, "dict"):  # Pydantic v1
                            serializable_messages.append(msg.dict())
                        elif hasattr(msg, "model_dump"):  # Pydantic v2
                            serializable_messages.append(msg.model_dump())
                        else:
                            # Fallback for plain objects
                            serializable_messages.append({
                                "type": msg.__class__.__name__,
                                "content": str(msg.content) if hasattr(msg, "content") else str(msg)
                            })
                    state_data["messages"] = serializable_messages

        return final_state or {}

    def run(self, product_brief: dict, thread_id: str | None = None) -> dict[str, Any]:
        """Ch·∫°y quy tr√¨nh l√†m vi·ªác c·ªßa vision agent (sync version).

        Args:
            product_brief: Product brief t·ª´ gatherer_agent (dict ch·ª©a product info)
            thread_id: ID ƒë·ªÉ resume state (n·∫øu None, d√πng session_id ho·∫∑c default)

        Returns:
            dict: Tr·∫°ng th√°i cu·ªëi c√πng ch·ª©a product_vision v√† summary
        """
        # Check if WebSocket mode is enabled
        if self.use_websocket:
            print(f"[VisionAgent.run] WebSocket mode detected - using websocket_helper", flush=True)

            # Import websocket helper
            from app.core.websocket_helper import websocket_helper

            # Run async version in dedicated WebSocket loop
            print(f"[VisionAgent.run] Scheduling in WebSocket helper loop...", flush=True)
            result = websocket_helper.run_coroutine(
                self.run_async(product_brief, thread_id),
                timeout=660  # 11 minutes
            )
            print(f"[VisionAgent.run] Execution completed!", flush=True)
            return result

        # Terminal mode: sync execution
        print(f"[VisionAgent.run] Terminal mode - sync execution", flush=True)

        if thread_id is None:
            thread_id = self.session_id or "default_vision_thread"

        initial_state = VisionState(product_brief=product_brief)

        # Build metadata for Langfuse tracing with session_id and user_id
        metadata = {}
        if self.session_id:
            metadata["langfuse_session_id"] = self.session_id
        if self.user_id:
            metadata["langfuse_user_id"] = self.user_id
        # Add tags
        metadata["langfuse_tags"] = ["vision_agent"]

        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": [self.langfuse_handler],
            "metadata": metadata,  # Pass session_id/user_id via metadata
            "recursion_limit": 50,
        }

        final_state = None
        for output in self.graph.stream(
            initial_state.model_dump(),
            config=config,
        ):
            final_state = output

        # Convert messages to serializable format before returning
        if final_state:
            # Extract the actual state from the output (it's wrapped in a node key)
            for node_name, state_data in final_state.items():
                if isinstance(state_data, dict) and "messages" in state_data:
                    # Convert BaseMessage objects to dicts
                    serializable_messages = []
                    for msg in state_data.get("messages", []):
                        if hasattr(msg, "dict"):  # Pydantic v1
                            serializable_messages.append(msg.dict())
                        elif hasattr(msg, "model_dump"):  # Pydantic v2
                            serializable_messages.append(msg.model_dump())
                        else:
                            # Fallback for plain objects
                            serializable_messages.append(
                                {
                                    "type": msg.__class__.__name__,
                                    "content": (
                                        str(msg.content)
                                        if hasattr(msg, "content")
                                        else str(msg)
                                    ),
                                }
                            )
                    state_data["messages"] = serializable_messages

        return final_state or {}
