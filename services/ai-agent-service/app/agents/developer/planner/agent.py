"""
Planner Agent

Main PlannerAgent class vá»›i LangGraph workflow cho 4-phase planning process.
"""

import os
from typing import Any

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langfuse.langchain import CallbackHandler
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph

from .nodes import (
    analyze_codebase,
    finalize,
    generate_plan,
    initialize,
    map_dependencies,
    parse_task,
    validate_plan,
)
from .state import PlannerState

# Load environment variables
load_dotenv()


class PlannerAgent:
    """
    Planner Agent - PhÃ¢n tÃ­ch task requirements vÃ  táº¡o detailed implementation plan.

    Workflow:
    START â†’ initialize â†’ parse_task â†’ analyze_codebase â†’ map_dependencies â†’
    generate_plan â†’ validate_plan â†’ finalize â†’ END

    Vá»›i validation loop: validate_plan cÃ³ thá»ƒ loop back Ä‘áº¿n analyze_codebase
    """

    def __init__(
        self,
        model: str | None = None,
        session_id: str | None = None,
        user_id: str | None = None,
    ):
        """
        Initialize PlannerAgent.

        Args:
            model: Model name (default: gpt-4o)
            session_id: Session ID cho Langfuse tracing
            user_id: User ID cho Langfuse tracing
        """
        self.model_name = model or "gpt-4o"
        self.session_id = session_id
        self.user_id = user_id

        # Setup Langfuse tracing (optional)
        try:
            if os.getenv("LANGFUSE_SECRET_KEY") and os.getenv("LANGFUSE_PUBLIC_KEY"):
                self.langfuse_handler = CallbackHandler(
                    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
                    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
                    host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
                    session_id=session_id,
                    user_id=user_id,
                )
            else:
                self.langfuse_handler = None
        except Exception as e:
            print(f"âš ï¸  Langfuse not configured: {e}")
            self.langfuse_handler = None

        # Build LangGraph workflow
        self.graph = self._build_graph()

    def _llm(self, model: str = "gpt-4o", temperature: float = 0.3) -> ChatOpenAI:
        """Create LLM instance."""
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL"),
        )

    def _build_graph(self) -> StateGraph:
        """Build LangGraph workflow cho planner."""
        graph_builder = StateGraph(PlannerState)

        # Add nodes
        graph_builder.add_node("initialize", initialize)
        graph_builder.add_node("parse_task", parse_task)
        graph_builder.add_node("analyze_codebase", analyze_codebase)
        graph_builder.add_node("map_dependencies", map_dependencies)
        graph_builder.add_node("generate_plan", generate_plan)
        graph_builder.add_node("validate_plan", validate_plan)
        graph_builder.add_node("finalize", finalize)

        # Add edges
        graph_builder.add_edge(START, "initialize")
        graph_builder.add_edge("initialize", "parse_task")
        graph_builder.add_edge("parse_task", "analyze_codebase")
        graph_builder.add_edge("analyze_codebase", "map_dependencies")
        graph_builder.add_edge("map_dependencies", "generate_plan")
        graph_builder.add_edge("generate_plan", "validate_plan")

        # Conditional edges for validation loop
        graph_builder.add_conditional_edges("validate_plan", self.validate_branch)
        graph_builder.add_edge("finalize", END)

        # Setup checkpointer
        checkpointer = MemorySaver()
        return graph_builder.compile(checkpointer=checkpointer)

    def validate_branch(self, state: PlannerState) -> str:
        """
        Conditional branch sau validate_plan node.

        Logic:
        - Náº¿u can_proceed = True â†’ finalize
        - Náº¿u can_proceed = False vÃ  current_iteration < max_iterations â†’ analyze_codebase (retry)
        - Náº¿u can_proceed = False vÃ  current_iteration >= max_iterations â†’ finalize (force)

        Args:
            state: PlannerState vá»›i validation results

        Returns:
            Next node name
        """
        print("\nğŸ”€ Validation Branch Decision:")
        print(f"   Can Proceed: {state.can_proceed}")
        print(f"   Validation Score: {state.validation_score:.2f}")
        print(f"   Current Iteration: {state.current_iteration}")
        print(f"   Max Iterations: {state.max_iterations}")
        print(f"   Issues: {len(state.validation_issues)}")

        if state.can_proceed:
            print("   â†’ Decision: FINALIZE (validation passed)")
            return "finalize"
        elif state.current_iteration < state.max_iterations:
            print(
                f"   â†’ Decision: RETRY (iteration {state.current_iteration}/{state.max_iterations})"
            )
            return "analyze_codebase"  # Loop back to analysis
        else:
            print("   â†’ Decision: FORCE FINALIZE (max iterations reached)")
            return "finalize"

    def run(
        self,
        task_description: str,
        codebase_context: str = "",
        codebase_path: str = "",
        thread_id: str | None = None,
    ) -> dict[str, Any]:
        """
        Run planner workflow.

        Args:
            task_description: Task description tá»« product backlog
            codebase_context: Additional codebase context
            codebase_path: Path to codebase for analysis (empty = use default)
            thread_id: Thread ID cho checkpointer (Ä‘á»ƒ resume)

        Returns:
            Dict vá»›i final_plan vÃ  metadata
        """
        if thread_id is None:
            thread_id = self.session_id or "default"

        # Create initial state
        initial_state = PlannerState(
            task_description=task_description,
            codebase_context=codebase_context,
            codebase_path=codebase_path,
        )

        # Build metadata for Langfuse tracing
        metadata = {}
        if self.session_id:
            metadata["langfuse_session_id"] = self.session_id
        if self.user_id:
            metadata["langfuse_user_id"] = self.user_id
        metadata["langfuse_tags"] = ["planner_agent"]

        # Setup config with optional Langfuse callback
        callbacks = []
        if self.langfuse_handler:
            callbacks.append(self.langfuse_handler)

        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": callbacks,
            "metadata": metadata,
            "recursion_limit": 50,
        }

        print("\n" + "=" * 80)
        print("ğŸš€ PLANNER AGENT STARTED")
        print("=" * 80)
        print(f"ğŸ“ Task: {task_description[:100]}...")
        print(f"ğŸ”— Thread ID: {thread_id}")
        print("=" * 80 + "\n")

        try:
            # Stream agent execution
            final_state = None
            step_count = 0

            for output in self.graph.stream(
                initial_state.model_dump(),
                config=config,
            ):
                step_count += 1
                final_state = output

                # Log progress
                if isinstance(output, dict):
                    for node_name, node_output in output.items():
                        if isinstance(node_output, dict) and "status" in node_output:
                            print(
                                f"ğŸ“ Step {step_count}: {node_name} - {node_output['status']}"
                            )

            # Extract final result
            if final_state and isinstance(final_state, dict):
                # Get the last node's output
                last_node_output = list(final_state.values())[-1]

                # Get implementation plan object
                implementation_plan = last_node_output.get("implementation_plan")

                result = {
                    "success": True,
                    "final_plan": last_node_output.get("final_plan", {}),
                    "ready_for_implementation": last_node_output.get(
                        "ready_for_implementation", False
                    ),
                    "task_id": implementation_plan.task_id
                    if implementation_plan
                    else "",
                    "complexity_score": implementation_plan.complexity_score
                    if implementation_plan
                    else 0,
                    "estimated_hours": implementation_plan.total_estimated_hours
                    if implementation_plan
                    else 0,
                    "story_points": implementation_plan.story_points
                    if implementation_plan
                    else 0,
                    "validation_score": last_node_output.get("validation_score", 0.0),
                    "status": last_node_output.get("status", "unknown"),
                    "iterations": last_node_output.get("current_iteration", 0),
                    "metadata": {
                        "planner_version": "1.0",
                        "total_steps": step_count,
                        "thread_id": thread_id,
                    },
                }

                print("\n" + "=" * 80)
                print("âœ… PLANNER AGENT COMPLETED")
                print("=" * 80)
                print(f"ğŸ“‹ Task ID: {result['task_id']}")
                print(f"ğŸ“Š Complexity: {result['complexity_score']}/10")
                print(
                    f"â±ï¸  Estimated: {result['estimated_hours']} hours ({result['story_points']} SP)"
                )
                print(
                    f"âœ… Ready for Implementation: {result['ready_for_implementation']}"
                )
                print(f"ğŸ“ˆ Validation Score: {result['validation_score']:.1%}")
                print(f"ğŸ”„ Iterations: {result['iterations']}")
                print("=" * 80 + "\n")

                return result
            else:
                raise Exception("No final state received from workflow")

        except Exception as e:
            print(f"\nâŒ PLANNER AGENT ERROR: {e}")
            return {
                "success": False,
                "error": str(e),
                "final_plan": {},
                "ready_for_implementation": False,
                "metadata": {
                    "planner_version": "1.0",
                    "thread_id": thread_id,
                    "error_occurred": True,
                },
            }
