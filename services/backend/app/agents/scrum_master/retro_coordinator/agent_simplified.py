"""Simplified Retro Coordinator Agent - Focus on generating project rules.

TraDS ============= Simplified workflow:
1. Get sprint data (metrics + blockers) from DB
2. Analyze with LLM to generate rules
3. Save rules to ProjectRules table
==============================
"""

import os
import json
from typing import Optional
from uuid import UUID
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from sqlmodel import Session
from dotenv import load_dotenv

load_dotenv()

from .state import RetroState
from .schemas import ProjectRulesOutput
from .tools import get_sprint_blockers, get_sprint_metrics, update_project_rules


class RetroCoordinatorAgent:
    """Simplified Retro Coordinator Agent."""

    def __init__(self, session: Session):
        """Initialize agent with database session."""
        self.session = session
        self.graph = self._build_graph()

    def _llm(self, temperature: float = 0.7) -> ChatOpenAI:
        """Initialize LLM."""
        return ChatOpenAI(
            model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
            temperature=temperature,
            api_key=os.getenv("OPENAI_API_KEY"),
        )

    def _build_graph(self) -> StateGraph:
        """Build simplified workflow."""
        workflow = StateGraph(RetroState)

        workflow.add_node("collect_data", self._collect_data_node)
        workflow.add_node("generate_agent_reports", self._generate_agent_reports_node)
        workflow.add_node("analyze_and_generate_rules", self._analyze_node)
        workflow.add_node("save_rules", self._save_rules_node)

        workflow.set_entry_point("collect_data")
        workflow.add_edge("collect_data", "generate_agent_reports")
        workflow.add_edge("generate_agent_reports", "analyze_and_generate_rules")
        workflow.add_edge("analyze_and_generate_rules", "save_rules")
        workflow.add_edge("save_rules", END)

        return workflow.compile()

    def _collect_data_node(self, state: RetroState) -> RetroState:
        """Collect sprint metrics and blockers from DB."""
        print("\nðŸ“Š Collecting sprint data from database...")

        try:
            sprint_id = UUID(state["sprint_id"])

            # Get metrics
            metrics = get_sprint_metrics(self.session, sprint_id)
            state["sprint_metrics"] = metrics
            print(f"âœ… Metrics: {metrics.get('completed_tasks')}/{metrics.get('total_tasks')} tasks, {metrics.get('completed_points')}/{metrics.get('total_points')} points")

            # Get blockers
            blockers = get_sprint_blockers(self.session, sprint_id)
            state["blockers"] = blockers
            print(f"âœ… Blockers: {len(blockers)} found")

        except Exception as e:
            state["error"] = f"Error collecting data: {e}"
            print(f"âŒ {state['error']}")

        return state

    def _generate_agent_reports_node(self, state: RetroState) -> RetroState:
        """Generate individual agent reports from sprint data."""
        print("\nðŸ“ Generating agent reports...")

        try:
            metrics = state.get("sprint_metrics", {})
            blockers = state.get("blockers", [])
            user_feedback = state.get("user_feedback", "")

            # Prepare data for LLM
            metrics_json = json.dumps(metrics, indent=2)
            blockers_json = json.dumps(blockers, indent=2)

            # Categorize blockers by type
            dev_blockers = [b for b in blockers if b.get("type") == "DEV_BLOCKER"]
            test_blockers = [b for b in blockers if b.get("type") == "TEST_BLOCKER"]

            # Create structured LLM
            from .schemas import AgentReportsOutput
            structured_llm = self._llm().with_structured_output(AgentReportsOutput)

            # Build prompt
            system_prompt = """Báº¡n lÃ  Scrum Master táº¡o bÃ¡o cÃ¡o cho tá»«ng agent trong sprint retrospective.

Táº¡o bÃ¡o cÃ¡o cho 3 agents (PO, Developer, Tester) vá»›i format:
âœ… ÄÃ£ hoÃ n thÃ nh:
â€¢ ...
â€¢ ...

ðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:
â€¢ ...
â€¢ ...

Dá»±a trÃªn:
- Sprint metrics (tasks, story points)
- Blockers tá»« team
- PO feedback (náº¿u cÃ³)

Viáº¿t báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n, cá»¥ thá»ƒ."""

            human_prompt = f"""Táº¡o bÃ¡o cÃ¡o cho tá»«ng agent:

METRICS:
{metrics_json}

BLOCKERS Tá»ª DEVELOPERS ({len(dev_blockers)} blockers):
{json.dumps(dev_blockers, indent=2)}

BLOCKERS Tá»ª TESTERS ({len(test_blockers)} blockers):
{json.dumps(test_blockers, indent=2)}

PO FEEDBACK:
{user_feedback if user_feedback else "KhÃ´ng cÃ³"}

Táº¡o bÃ¡o cÃ¡o riÃªng cho PO, Developer vÃ  Tester."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]

            result = structured_llm.invoke(messages)

            # Fallback messages for empty reports
            fallback_po = "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Sprint Ä‘ang trong quÃ¡ trÃ¬nh thá»±c hiá»‡n\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t"
            fallback_dev = "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Team Ä‘ang tÃ­ch cá»±c phÃ¡t triá»ƒn cÃ¡c tÃ­nh nÄƒng\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ thÃ´ng tin vá» blockers vÃ  tiáº¿n Ä‘á»™"
            fallback_tester = "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Äang chuáº©n bá»‹ test cases vÃ  mÃ´i trÆ°á»ng test\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ dá»¯ liá»‡u testing Ä‘á»ƒ phÃ¢n tÃ­ch"

            # Store reports in state with fallback
            state["agent_reports"] = {
                "po": result.po_report if result.po_report and len(result.po_report.strip()) > 20 else fallback_po,
                "dev": result.dev_report if result.dev_report and len(result.dev_report.strip()) > 20 else fallback_dev,
                "tester": result.tester_report if result.tester_report and len(result.tester_report.strip()) > 20 else fallback_tester
            }

            print("âœ… Agent reports generated")
            print(f"   PO: {state['agent_reports']['po'][:50]}...")
            print(f"   Dev: {state['agent_reports']['dev'][:50]}...")
            print(f"   Tester: {state['agent_reports']['tester'][:50]}...")

        except Exception as e:
            state["error"] = f"Error generating reports: {e}"
            print(f"âŒ {state['error']}")
            import traceback
            traceback.print_exc()

            # Set fallback reports on error
            state["agent_reports"] = {
                "po": "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Sprint Ä‘ang trong quÃ¡ trÃ¬nh thá»±c hiá»‡n\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t",
                "dev": "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Team Ä‘ang tÃ­ch cá»±c phÃ¡t triá»ƒn cÃ¡c tÃ­nh nÄƒng\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ thÃ´ng tin vá» blockers vÃ  tiáº¿n Ä‘á»™",
                "tester": "âœ… ÄÃ£ hoÃ n thÃ nh:\nâ€¢ Äang chuáº©n bá»‹ test cases vÃ  mÃ´i trÆ°á»ng test\n\nðŸš§ Váº¥n Ä‘á» gáº·p pháº£i:\nâ€¢ ChÆ°a cÃ³ Ä‘á»§ dá»¯ liá»‡u testing Ä‘á»ƒ phÃ¢n tÃ­ch"
            }

        return state

    def _analyze_node(self, state: RetroState) -> RetroState:
        """Analyze sprint data and generate rules with LLM."""
        print("\nðŸ¤– Analyzing sprint and generating rules...")

        try:
            metrics = state.get("sprint_metrics", {})
            blockers = state.get("blockers", [])
            user_feedback = state.get("user_feedback", "")

            # Prepare data for LLM
            metrics_json = json.dumps(metrics, indent=2)
            blockers_json = json.dumps(blockers, indent=2)

            # Create structured LLM
            structured_llm = self._llm().with_structured_output(ProjectRulesOutput)

            # Build prompt with PO feedback integration
            system_prompt = """Báº¡n lÃ  Scrum Master chuyÃªn nghiá»‡p phÃ¢n tÃ­ch sprint retrospective.

Nhiá»‡m vá»¥:
1. Táº¡o tÃ³m táº¯t sprint overview (2-3 cÃ¢u) báº±ng tiáº¿ng Viá»‡t
2. Liá»‡t kÃª nhá»¯ng Ä‘iá»u tá»‘t (what went well) dáº¡ng bullet points - Káº¾T Há»¢P tá»« metrics, blockers VÃ€ feedback PO
3. TÃ³m táº¯t blockers theo loáº¡i (PO/Dev/Tester) - Káº¾T Há»¢P tá»« blockers DB VÃ€ feedback PO
4. Táº¡o quy táº¯c cáº£i tiáº¿n cho tá»«ng role (PO/Dev/Tester) cho sprint tiáº¿p theo

Quy táº¯c pháº£i:
- Cá»¥ thá»ƒ, cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c
- Dá»±a trÃªn blockers, metrics VÃ€ FEEDBACK Tá»ª PRODUCT OWNER
- Æ¯u tiÃªn nhá»¯ng gÃ¬ PO quan tÃ¢m (náº¿u cÃ³ feedback)
- NgÄƒn cháº·n váº¥n Ä‘á» tÆ°Æ¡ng tá»± trong tÆ°Æ¡ng lai
- Viáº¿t báº±ng tiáº¿ng Viá»‡t
- Dáº¡ng bullet points"""

            # Build human prompt
            human_prompt_parts = ["PhÃ¢n tÃ­ch sprint retrospective:\n"]

            human_prompt_parts.append(f"SPRINT METRICS:\n{metrics_json}\n")
            human_prompt_parts.append(f"BLOCKERS Tá»ª TEAM (Dev/Tester):\n{blockers_json}\n")

            if user_feedback and user_feedback.strip():
                human_prompt_parts.append(f"FEEDBACK Tá»ª PRODUCT OWNER:\n{user_feedback}\n")
                human_prompt_parts.append("âš ï¸ QUAN TRá»ŒNG: Káº¿t há»£p feedback PO vÃ o 'what went well' vÃ  'blockers summary'. Náº¿u PO nÃ³i vá» váº¥n Ä‘á» gÃ¬, pháº£i xuáº¥t hiá»‡n trong rules.\n")

            human_prompt_parts.append("Táº¡o overview, what went well (káº¿t há»£p metrics + PO feedback), blockers summary (káº¿t há»£p blockers DB + PO feedback) vÃ  rules cho PO/Dev/Tester.")

            human_prompt = "\n".join(human_prompt_parts)

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]

            result = structured_llm.invoke(messages)

            # Update state
            state["overview_summary"] = result.overview_summary
            state["what_went_well"] = result.what_went_well
            state["blockers_summary"] = result.blockers_summary
            state["po_rules"] = result.po_rules
            state["dev_rules"] = result.dev_rules
            state["tester_rules"] = result.tester_rules

            print("âœ… Rules generated successfully")

        except Exception as e:
            state["error"] = f"Error analyzing: {e}"
            print(f"âŒ {state['error']}")
            import traceback
            traceback.print_exc()

        return state

    def _save_rules_node(self, state: RetroState) -> RetroState:
        """Save rules to database."""
        print("\nðŸ’¾ Saving rules to database...")

        try:
            project_id = UUID(state["project_id"])
            po_rules = state.get("po_rules", "")
            dev_rules = state.get("dev_rules", "")
            tester_rules = state.get("tester_rules", "")

            success = update_project_rules(
                self.session,
                project_id,
                po_rules,
                dev_rules,
                tester_rules
            )

            if success:
                print("âœ… Rules saved to database")

                # Build final summary
                metrics = state.get("sprint_metrics", {})
                agent_reports = state.get("agent_reports", {})
                print(f"\nðŸ“¦ Final agent_reports being saved:")
                print(f"   Keys: {list(agent_reports.keys())}")
                print(f"   PO length: {len(agent_reports.get('po', ''))}")
                print(f"   Dev length: {len(agent_reports.get('dev', ''))}")
                print(f"   Tester length: {len(agent_reports.get('tester', ''))}")

                state["retro_summary"] = {
                    "status": "success",
                    "sprint_metrics": metrics,
                    "agent_reports": agent_reports,
                    "overview_summary": state.get("overview_summary"),
                    "what_went_well": state.get("what_went_well"),
                    "blockers_summary": state.get("blockers_summary"),
                    "blockers": state.get("blockers", []),
                    "po_rules": po_rules,
                    "dev_rules": dev_rules,
                    "tester_rules": tester_rules,
                }
            else:
                state["error"] = "Failed to save rules"

        except Exception as e:
            state["error"] = f"Error saving rules: {e}"
            print(f"âŒ {state['error']}")

        return state

    def run(self, sprint_id: str, project_id: str, user_feedback: Optional[str] = None) -> dict:
        """Run retrospective analysis.

        Args:
            sprint_id: Sprint UUID
            project_id: Project UUID
            user_feedback: Optional user feedback to refine rules

        Returns:
            Retrospective summary
        """
        print("\n" + "="*80)
        print("ðŸš€ RETRO COORDINATOR AGENT - SIMPLIFIED")
        print("="*80)

        try:
            initial_state: RetroState = {
                "sprint_id": sprint_id,
                "project_id": project_id,
                "user_feedback": user_feedback,
                "sprint_metrics": None,
                "blockers": None,
                "agent_reports": None,  # NEW
                "what_went_well": None,
                "blockers_summary": None,
                "overview_summary": None,
                "po_rules": None,
                "dev_rules": None,
                "tester_rules": None,
                "retro_summary": None,
                "error": None,
            }

            final_state = self.graph.invoke(initial_state)

            if final_state.get("error"):
                return {
                    "status": "error",
                    "error": final_state["error"]
                }

            return {
                "status": "success",
                "data": final_state.get("retro_summary")
            }

        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            return {
                "status": "error",
                "error": str(e)
            }


def create_retro_coordinator_agent(session: Session) -> RetroCoordinatorAgent:
    """Create agent instance."""
    return RetroCoordinatorAgent(session=session)
